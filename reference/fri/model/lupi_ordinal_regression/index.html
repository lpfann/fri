



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../../docs/favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.2">
    
    
      
        <title>Lupi Ordinal Regression - fri</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.30686662.css">
      
      
    
    
      <script src="../../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#module-frimodellupi_ordinal_regression" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../.." title="fri" class="md-header-nav__button md-logo">
          
            <img src="../../../../docs/logo.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              fri
            </span>
            <span class="md-header-nav__topic">
              
                Lupi Ordinal Regression
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/lpfann/fri/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    lpfann/fri
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../.." title="fri" class="md-nav__button md-logo">
      
        <img src="../../../../docs/logo.png" width="48" height="48">
      
    </a>
    fri
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/lpfann/fri/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    lpfann/fri
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/Guide/" title="Guide" class="md-nav__link">
      Guide
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/background/" title="Background" class="md-nav__link">
      Background
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/citing_FRI/" title="Citing Fri" class="md-nav__link">
      Citing Fri
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Reference
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1" checked>
    
    <label class="md-nav__link" for="nav-5-1">
      Fri
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        Fri
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../compute/" title="Compute" class="md-nav__link">
      Compute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../main/" title="Main" class="md-nav__link">
      Main
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../parameter_searcher/" title="Parameter Searcher" class="md-nav__link">
      Parameter Searcher
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../plot/" title="Plot" class="md-nav__link">
      Plot
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-7" type="checkbox" id="nav-5-1-7" checked>
    
    <label class="md-nav__link" for="nav-5-1-7">
      Model
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-7">
        Model
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../base_cvxproblem/" title="Base Cvxproblem" class="md-nav__link">
      Base Cvxproblem
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_initmodel/" title="Base Initmodel" class="md-nav__link">
      Base Initmodel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_lupi/" title="Base Lupi" class="md-nav__link">
      Base Lupi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_type/" title="Base Type" class="md-nav__link">
      Base Type
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../classification/" title="Classification" class="md-nav__link">
      Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lupi_classification/" title="Lupi Classification" class="md-nav__link">
      Lupi Classification
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Lupi Ordinal Regression
      </label>
    
    <a href="./" title="Lupi Ordinal Regression" class="md-nav__link md-nav__link--active">
      Lupi Ordinal Regression
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_bin_mapping" class="md-nav__link">
    get_bin_mapping
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression" class="md-nav__link">
    LUPI_OrdinalRegression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_all_parameters" class="md-nav__link">
    get_all_parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_all_relax_factors" class="md-nav__link">
    get_all_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_parameter" class="md-nav__link">
    get_chosen_parameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_relax_factors" class="md-nav__link">
    get_chosen_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_relaxed_constraints" class="md-nav__link">
    get_relaxed_constraints
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postprocessing" class="md-nav__link">
    postprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_constraint" class="md-nav__link">
    relax_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_factors" class="md-nav__link">
    relax_factors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression_relevance_bound" class="md-nav__link">
    LUPI_OrdinalRegression_Relevance_Bound
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aggregate_max_candidates" class="md-nav__link">
    aggregate_max_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregate_min_candidates" class="md-nav__link">
    aggregate_min_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_lower_bound_problem" class="md-nav__link">
    generate_lower_bound_problem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_upper_bound_problem" class="md-nav__link">
    generate_upper_bound_problem
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_constraint" class="md-nav__link">
    add_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_lb" class="md-nav__link">
    init_objective_LB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_ub" class="md-nav__link">
    init_objective_UB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing_data" class="md-nav__link">
    preprocessing_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solve" class="md-nav__link">
    solve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression_svm" class="md-nav__link">
    LUPI_OrdinalRegression_SVM
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameter" class="md-nav__link">
    hyperparameter
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lupi_regression/" title="Lupi Regression" class="md-nav__link">
      Lupi Regression
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../ordinal_regression/" title="Ordinal Regression" class="md-nav__link">
      Ordinal Regression
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../regression/" title="Regression" class="md-nav__link">
      Regression
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-8" type="checkbox" id="nav-5-1-8">
    
    <label class="md-nav__link" for="nav-5-1-8">
      Toydata
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-8">
        Toydata
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/gen_data/" title="Gen Data" class="md-nav__link">
      Gen Data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/gen_lupi/" title="Gen Lupi" class="md-nav__link">
      Gen Lupi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_bin_mapping" class="md-nav__link">
    get_bin_mapping
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression" class="md-nav__link">
    LUPI_OrdinalRegression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_all_parameters" class="md-nav__link">
    get_all_parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_all_relax_factors" class="md-nav__link">
    get_all_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_parameter" class="md-nav__link">
    get_chosen_parameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_relax_factors" class="md-nav__link">
    get_chosen_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_relaxed_constraints" class="md-nav__link">
    get_relaxed_constraints
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postprocessing" class="md-nav__link">
    postprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_constraint" class="md-nav__link">
    relax_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_factors" class="md-nav__link">
    relax_factors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression_relevance_bound" class="md-nav__link">
    LUPI_OrdinalRegression_Relevance_Bound
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aggregate_max_candidates" class="md-nav__link">
    aggregate_max_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregate_min_candidates" class="md-nav__link">
    aggregate_min_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_lower_bound_problem" class="md-nav__link">
    generate_lower_bound_problem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_upper_bound_problem" class="md-nav__link">
    generate_upper_bound_problem
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_constraint" class="md-nav__link">
    add_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_lb" class="md-nav__link">
    init_objective_LB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_ub" class="md-nav__link">
    init_objective_UB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing_data" class="md-nav__link">
    preprocessing_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solve" class="md-nav__link">
    solve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_ordinalregression_svm" class="md-nav__link">
    LUPI_OrdinalRegression_SVM
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameter" class="md-nav__link">
    hyperparameter
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lpfann/fri/edit/master/docs/reference/fri/model/lupi_ordinal_regression.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="module-frimodellupi_ordinal_regression">Module fri.model.lupi_ordinal_regression</h1>
<p>??? example "View Source"
        from itertools import product</p>
<pre><code>    import cvxpy as cvx

    import numpy as np

    from sklearn.metrics import make_scorer

    from sklearn.utils import check_X_y



    from fri.model.base_lupi import (

        LUPI_Relevance_CVXProblem,

        split_dataset,

        is_lupi_feature,

    )

    from fri.model.ordinal_regression import (

        OrdinalRegression_Relevance_Bound,

        ordinal_scores,

    )

    from .base_initmodel import LUPI_InitModel

    from .base_type import ProblemType





    class LUPI_OrdinalRegression(ProblemType):

        def __init__(self, **kwargs):

            super().__init__(**kwargs)

            self._lupi_features = None



        @property

        def lupi_features(self):

            return self._lupi_features



        @classmethod

        def parameters(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]



        @property

        def get_initmodel_template(cls):

            return LUPI_OrdinalRegression_SVM



        @property

        def get_cvxproblem_template(cls):

            return LUPI_OrdinalRegression_Relevance_Bound



        def relax_factors(cls):

            return ["loss_slack", "w_l1_slack"]



        def preprocessing(self, data, lupi_features=None):

            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)

            if np.min(y) &gt; 0:

                print("First ordinal class has index &gt; 0. Shifting index...")

                y = y - np.min(y)



            return X, y





    class LUPI_OrdinalRegression_SVM(LUPI_InitModel):

        @classmethod

        def hyperparameter(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]



        def fit(self, X_combined, y, lupi_features=None):

            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape

            self.classes_ = np.unique(y)



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            get_original_bin_name, n_bins = get_bin_mapping(y)

            n_boundaries = n_bins - 1



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b_s = cvx.Variable(shape=(n_boundaries), name="bias")



            w_priv = cvx.Variable(shape=(self.lupi_features, 2), name="w_priv")

            d_priv = cvx.Variable(shape=(2), name="bias_priv")



            slack_left = cvx.Variable(shape=(n), name="slack_left")

            slack_right = cvx.Variable(shape=(n), name="slack_right")



            def priv_function(bin, sign):

                indices = np.where(y == get_original_bin_name[bin])

                return X_priv[indices] * w_priv[:, sign] + d_priv[sign]



            # L1 norm regularization of both functions with 1 scaling constant

            priv_l1_1 = cvx.norm(w_priv[:, 0], 1)

            priv_l1_2 = cvx.norm(w_priv[:, 1], 1)

            w_priv_l1 = priv_l1_1 + priv_l1_2

            w_l1 = cvx.norm(w, 1)

            weight_regularization = 0.5 * (w_l1 + scaling_lupi_w * w_priv_l1)



            constraints = []

            loss = 0



            for left_bin in range(0, n_bins - 1):

                indices = np.where(y == get_original_bin_name[left_bin])

                constraints.append(

                    X[indices] * w - b_s[left_bin] - slack_left[indices]

                    &lt;= -1 + priv_function(left_bin, 0)

                )

                constraints.append(priv_function(left_bin, 0) &gt;= 0)

                loss += cvx.sum(priv_function(left_bin, 0))



            # Add constraints for slack into right neighboring bins

            for right_bin in range(1, n_bins):

                indices = np.where(y == get_original_bin_name[right_bin])

                constraints.append(

                    X[indices] * w - b_s[right_bin - 1] - slack_right[indices]

                    &gt;= +1 - priv_function(right_bin, 1)

                )

                constraints.append(priv_function(right_bin, 1) &gt;= 0)

                loss += cvx.sum(priv_function(right_bin, 1))



            for i_boundary in range(0, n_boundaries - 1):

                constraints.append(b_s[i_boundary] &lt;= b_s[i_boundary + 1])



            constraints.append(slack_left &gt;= 0)

            constraints.append(slack_right &gt;= 0)

            loss = scaling_lupi_loss * loss + cvx.sum(slack_left + slack_right)



            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            w = w.value

            b_s = b_s.value

            self.model_state = {

                "w": w,

                "b_s": b_s,

                "w_priv": w_priv.value,

                "d_priv": d_priv.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else

                "bin_boundaries": n_boundaries,

            }



            self.constraints = {

                "loss": loss.value,

                "w_l1": w_l1.value,

                "w_priv_l1": w_priv_l1.value,

                "priv_l1_1": priv_l1_1.value,

                "priv_l1_2": priv_l1_2.value,

            }

            return self



        def predict(self, X):



            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b_s = self.model_state["b_s"]



            scores = np.dot(X, w.T)[np.newaxis]

            bin_thresholds = np.append(b_s, np.inf)



            # If thresholds are smaller than score the value belongs to the bigger bin

            # after subtracting we check for positive elements

            indices = np.sum(scores.T - bin_thresholds &gt;= 0, -1)

            return self.classes_[indices]



        def score(self, X, y, error_type="mmae", return_error=False, **kwargs):



            X, y = check_X_y(X, y)



            prediction = self.predict(X)

            score = ordinal_scores(y, prediction, error_type, return_error=return_error)



            return score



        def make_scorer(self):

            # Use multiple scores for ordinal regression

            mze = make_scorer(ordinal_scores, error_type="mze")

            mae = make_scorer(ordinal_scores, error_type="mae")

            mmae = make_scorer(ordinal_scores, error_type="mmae")

            scorer = {"mze": mze, "mae": mae, "mmae": mmae}

            return scorer, "mmae"





    def get_bin_mapping(y):

        """

        Get ordered unique classes and corresponding mapping from old names

        Parameters

        ----------

        y: array of discrete values (int, str)



        Returns



        -------



        """

        classes_ = np.unique(y)

        original_bins = sorted(classes_)

        n_bins = len(original_bins)

        bins = np.arange(n_bins)

        get_old_bin = dict(zip(bins, original_bins))

        return get_old_bin, n_bins





    class LUPI_OrdinalRegression_Relevance_Bound(

        LUPI_Relevance_CVXProblem, OrdinalRegression_Relevance_Bound

    ):

        @classmethod

        def generate_lower_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_lower_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign in [1, -1]:

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_LB(sign=sign)

                    problem.isLowerBound = True

                    yield problem



        @classmethod

        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [0, 1]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem



        @classmethod

        def aggregate_min_candidates(cls, min_problems_candidates):

            vals = [candidate.solved_relevance for candidate in min_problems_candidates]

            # We take the max of mins because we need the necessary contribution over all functions

            min_value = max(vals)

            return min_value



        def _init_objective_LB_LUPI(self, sign=None, bin_index=None, **kwargs):



            self.add_constraint(

                sign * self.w_priv[self.lupi_index, :] &lt;= self.feature_relevance

            )



            self._objective = cvx.Minimize(self.feature_relevance)



        def _init_objective_UB_LUPI(self, sign=None, pos=None, **kwargs):



            self.add_constraint(

                self.feature_relevance &lt;= sign * self.w_priv[self.lupi_index, pos]

            )



            self._objective = cvx.Maximize(self.feature_relevance)



        def _init_constraints(self, parameters, init_model_constraints):



            # Upper constraints from initial model

            init_w_l1 = init_model_constraints["w_l1"]

            init_w_priv_l1 = init_model_constraints["w_priv_l1"]

            init_priv_l1_1 = init_model_constraints["priv_l1_1"]

            init_priv_l1_2 = init_model_constraints["priv_l1_2"]

            init_loss = init_model_constraints["loss"]



            get_original_bin_name, n_bins = get_bin_mapping(self.y)

            n_boundaries = n_bins - 1



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(self.d), name="w")

            b_s = cvx.Variable(shape=(n_boundaries), name="bias")



            w_priv = cvx.Variable(shape=(self.d_priv, 2), name="w_priv")

            d_priv = cvx.Variable(shape=(2), name="bias_priv")



            def priv_function(bin, sign):

                indices = np.where(self.y == get_original_bin_name[bin])

                return self.X_priv[indices] * w_priv[:, sign] + d_priv[sign]



            # L1 norm regularization of both functions with 1 scaling constant

            priv_l1_1 = cvx.norm(w_priv[:, 0], 1)

            priv_l1_2 = cvx.norm(w_priv[:, 1], 1)

            w_priv_l1 = priv_l1_1 + priv_l1_2

            w_l1 = cvx.norm(w, 1)



            slack_left = cvx.Variable(shape=(self.n), name="slack_left")

            slack_right = cvx.Variable(shape=(self.n), name="slack_right")



            loss = 0

            for left_bin in range(0, n_bins - 1):

                indices = np.where(self.y == get_original_bin_name[left_bin])

                self.add_constraint(

                    self.X[indices] * w - b_s[left_bin]

                    &lt;= -1 + priv_function(left_bin, 0) + slack_left[indices]

                )

                self.add_constraint(priv_function(left_bin, 0) &gt;= 0)

                loss += cvx.sum(priv_function(left_bin, 0))



            # Add constraints for slack into right neighboring bins

            for right_bin in range(1, n_bins):

                indices = np.where(self.y == get_original_bin_name[right_bin])

                self.add_constraint(

                    self.X[indices] * w - b_s[right_bin - 1]

                    &gt;= +1 - priv_function(right_bin, 1) - slack_right[indices]

                )

                self.add_constraint(priv_function(right_bin, 1) &gt;= 0)

                loss += cvx.sum(priv_function(right_bin, 1))



            loss = loss + cvx.sum(slack_left + slack_right)



            for i_boundary in range(0, n_boundaries - 1):

                self.add_constraint(b_s[i_boundary] &lt;= b_s[i_boundary + 1])



            self.add_constraint(

                w_l1 + w_priv_l1 &lt;= init_w_l1 + 0.5 * (init_w_priv_l1 + init_priv_l1_2)

            )

            # self.add_constraint(priv_l1_1 &lt;= init_priv_l1_1)

            # self.add_constraint(priv_l1_2 &lt;= init_priv_l1_2)



            self.add_constraint(slack_left &gt;= 0)

            self.add_constraint(slack_right &gt;= 0)

            self.add_constraint(loss &lt;= init_loss)



            self.w = w

            self.w_priv = w_priv

            self.feature_relevance = cvx.Variable(nonneg=True, name="Feature Relevance")
</code></pre>
<h2 id="functions">Functions</h2>
<h3 id="get_bin_mapping">get_bin_mapping</h3>
<pre><code class="python3">def get_bin_mapping(
    y
)
</code></pre>

<p>Get ordered unique classes and corresponding mapping from old names
Parameters</p>
<hr />
<p>y: array of discrete values (int, str)</p>
<p>Returns</p>
<hr />
<p>??? example "View Source"
        def get_bin_mapping(y):</p>
<pre><code>        """

        Get ordered unique classes and corresponding mapping from old names

        Parameters

        ----------

        y: array of discrete values (int, str)



        Returns



        -------



        """

        classes_ = np.unique(y)

        original_bins = sorted(classes_)

        n_bins = len(original_bins)

        bins = np.arange(n_bins)

        get_old_bin = dict(zip(bins, original_bins))

        return get_old_bin, n_bins
</code></pre>
<h2 id="classes">Classes</h2>
<h3 id="lupi_ordinalregression">LUPI_OrdinalRegression</h3>
<pre><code class="python3">class LUPI_OrdinalRegression(
    **kwargs
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_OrdinalRegression(ProblemType):</p>
<pre><code>        def __init__(self, **kwargs):

            super().__init__(**kwargs)

            self._lupi_features = None



        @property

        def lupi_features(self):

            return self._lupi_features



        @classmethod

        def parameters(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]



        @property

        def get_initmodel_template(cls):

            return LUPI_OrdinalRegression_SVM



        @property

        def get_cvxproblem_template(cls):

            return LUPI_OrdinalRegression_Relevance_Bound



        def relax_factors(cls):

            return ["loss_slack", "w_l1_slack"]



        def preprocessing(self, data, lupi_features=None):

            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)

            if np.min(y) &gt; 0:

                print("First ordinal class has index &gt; 0. Shifting index...")

                y = y - np.min(y)



            return X, y
</code></pre>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_type.ProblemType</li>
<li>abc.ABC</li>
</ul>
<h4 id="static-methods">Static methods</h4>
<h5 id="parameters">parameters</h5>
<pre><code class="python3">def parameters(

)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def parameters(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]
</code></pre>
<h4 id="instance-variables">Instance variables</h4>
<pre><code class="python3">get_cvxproblem_template
</code></pre>

<pre><code class="python3">get_initmodel_template
</code></pre>

<pre><code class="python3">lupi_features
</code></pre>

<h4 id="methods">Methods</h4>
<h5 id="get_all_parameters">get_all_parameters</h5>
<pre><code class="python3">def get_all_parameters(
    self
)
</code></pre>

<p>??? example "View Source"
            def get_all_parameters(self):</p>
<pre><code>            return {p: self.get_chosen_parameter(p) for p in self.parameters()}
</code></pre>
<h5 id="get_all_relax_factors">get_all_relax_factors</h5>
<pre><code class="python3">def get_all_relax_factors(
    self
)
</code></pre>

<p>??? example "View Source"
            def get_all_relax_factors(self):</p>
<pre><code>            return {p: self.get_chosen_relax_factors(p) for p in self.relax_factors()}
</code></pre>
<h5 id="get_chosen_parameter">get_chosen_parameter</h5>
<pre><code class="python3">def get_chosen_parameter(
    self,
    p
)
</code></pre>

<p>??? example "View Source"
            def get_chosen_parameter(self, p):</p>
<pre><code>            try:

                return [

                    self.chosen_parameters_[p]

                ]  # We return list for param search function

            except:

                # # TODO: rewrite the parameter logic

                # # TODO: move this to subclass

                if p == "scaling_lupi_w":

                    # return [0.1, 1, 10, 100, 1000]

                    return scipy.stats.reciprocal(a=1e-15, b=1e10)

                # if p == "scaling_lupi_loss":

                #    # value 0&gt;p&lt;1 causes standard svm solution

                #    # p&gt;1 encourages usage of lupi function

                #    return scipy.stats.reciprocal(a=1e-15, b=1e15)

                if p == "C":

                    return scipy.stats.reciprocal(a=1e-5, b=1e5)

                if p == "epsilon":

                    return [0, 0.001, 0.01, 0.1, 1, 10, 100]

                else:

                    return scipy.stats.reciprocal(a=1e-10, b=1e10)
</code></pre>
<h5 id="get_chosen_relax_factors">get_chosen_relax_factors</h5>
<pre><code class="python3">def get_chosen_relax_factors(
    self,
    p
)
</code></pre>

<p>??? example "View Source"
            def get_chosen_relax_factors(self, p):</p>
<pre><code>            try:

                factor = self.relax_factors_[p]

            except KeyError:

                try:

                    factor = self.relax_factors_[p + "_slack"]

                except KeyError:

                    factor = 0.1

            if factor &lt; 0:

                raise ValueError("Slack Factor multiplier is positive!")

            return factor
</code></pre>
<h5 id="get_relaxed_constraints">get_relaxed_constraints</h5>
<pre><code class="python3">def get_relaxed_constraints(
    self,
    constraints
)
</code></pre>

<p>??? example "View Source"
            def get_relaxed_constraints(self, constraints):</p>
<pre><code>            return {c: self.relax_constraint(c, v) for c, v in constraints.items()}
</code></pre>
<h5 id="postprocessing">postprocessing</h5>
<pre><code class="python3">def postprocessing(
    self,
    bounds
)
</code></pre>

<p>??? example "View Source"
            def postprocessing(self, bounds):</p>
<pre><code>            return bounds
</code></pre>
<h5 id="preprocessing">preprocessing</h5>
<pre><code class="python3">def preprocessing(
    self,
    data,
    lupi_features=None
)
</code></pre>

<p>??? example "View Source"
            def preprocessing(self, data, lupi_features=None):</p>
<pre><code>            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)

            if np.min(y) &gt; 0:

                print("First ordinal class has index &gt; 0. Shifting index...")

                y = y - np.min(y)



            return X, y
</code></pre>
<h5 id="relax_constraint">relax_constraint</h5>
<pre><code class="python3">def relax_constraint(
    self,
    key,
    value
)
</code></pre>

<p>??? example "View Source"
            def relax_constraint(self, key, value):</p>
<pre><code>            return value * (1 + self.get_chosen_relax_factors(key))
</code></pre>
<h5 id="relax_factors">relax_factors</h5>
<pre><code class="python3">def relax_factors(
    cls
)
</code></pre>

<p>??? example "View Source"
            def relax_factors(cls):</p>
<pre><code>            return ["loss_slack", "w_l1_slack"]
</code></pre>
<h3 id="lupi_ordinalregression_relevance_bound">LUPI_OrdinalRegression_Relevance_Bound</h3>
<pre><code class="python3">class LUPI_OrdinalRegression_Relevance_Bound(
    current_feature: int,
    data: tuple,
    hyperparameters,
    best_model_constraints,
    preset_model=None,
    best_model_state=None,
    probeID=-1
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_OrdinalRegression_Relevance_Bound(</p>
<pre><code>        LUPI_Relevance_CVXProblem, OrdinalRegression_Relevance_Bound

    ):

        @classmethod

        def generate_lower_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_lower_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign in [1, -1]:

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_LB(sign=sign)

                    problem.isLowerBound = True

                    yield problem



        @classmethod

        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [0, 1]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem



        @classmethod

        def aggregate_min_candidates(cls, min_problems_candidates):

            vals = [candidate.solved_relevance for candidate in min_problems_candidates]

            # We take the max of mins because we need the necessary contribution over all functions

            min_value = max(vals)

            return min_value



        def _init_objective_LB_LUPI(self, sign=None, bin_index=None, **kwargs):



            self.add_constraint(

                sign * self.w_priv[self.lupi_index, :] &lt;= self.feature_relevance

            )



            self._objective = cvx.Minimize(self.feature_relevance)



        def _init_objective_UB_LUPI(self, sign=None, pos=None, **kwargs):



            self.add_constraint(

                self.feature_relevance &lt;= sign * self.w_priv[self.lupi_index, pos]

            )



            self._objective = cvx.Maximize(self.feature_relevance)



        def _init_constraints(self, parameters, init_model_constraints):



            # Upper constraints from initial model

            init_w_l1 = init_model_constraints["w_l1"]

            init_w_priv_l1 = init_model_constraints["w_priv_l1"]

            init_priv_l1_1 = init_model_constraints["priv_l1_1"]

            init_priv_l1_2 = init_model_constraints["priv_l1_2"]

            init_loss = init_model_constraints["loss"]



            get_original_bin_name, n_bins = get_bin_mapping(self.y)

            n_boundaries = n_bins - 1



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(self.d), name="w")

            b_s = cvx.Variable(shape=(n_boundaries), name="bias")



            w_priv = cvx.Variable(shape=(self.d_priv, 2), name="w_priv")

            d_priv = cvx.Variable(shape=(2), name="bias_priv")



            def priv_function(bin, sign):

                indices = np.where(self.y == get_original_bin_name[bin])

                return self.X_priv[indices] * w_priv[:, sign] + d_priv[sign]



            # L1 norm regularization of both functions with 1 scaling constant

            priv_l1_1 = cvx.norm(w_priv[:, 0], 1)

            priv_l1_2 = cvx.norm(w_priv[:, 1], 1)

            w_priv_l1 = priv_l1_1 + priv_l1_2

            w_l1 = cvx.norm(w, 1)



            slack_left = cvx.Variable(shape=(self.n), name="slack_left")

            slack_right = cvx.Variable(shape=(self.n), name="slack_right")



            loss = 0

            for left_bin in range(0, n_bins - 1):

                indices = np.where(self.y == get_original_bin_name[left_bin])

                self.add_constraint(

                    self.X[indices] * w - b_s[left_bin]

                    &lt;= -1 + priv_function(left_bin, 0) + slack_left[indices]

                )

                self.add_constraint(priv_function(left_bin, 0) &gt;= 0)

                loss += cvx.sum(priv_function(left_bin, 0))



            # Add constraints for slack into right neighboring bins

            for right_bin in range(1, n_bins):

                indices = np.where(self.y == get_original_bin_name[right_bin])

                self.add_constraint(

                    self.X[indices] * w - b_s[right_bin - 1]

                    &gt;= +1 - priv_function(right_bin, 1) - slack_right[indices]

                )

                self.add_constraint(priv_function(right_bin, 1) &gt;= 0)

                loss += cvx.sum(priv_function(right_bin, 1))



            loss = loss + cvx.sum(slack_left + slack_right)



            for i_boundary in range(0, n_boundaries - 1):

                self.add_constraint(b_s[i_boundary] &lt;= b_s[i_boundary + 1])



            self.add_constraint(

                w_l1 + w_priv_l1 &lt;= init_w_l1 + 0.5 * (init_w_priv_l1 + init_priv_l1_2)

            )

            # self.add_constraint(priv_l1_1 &lt;= init_priv_l1_1)

            # self.add_constraint(priv_l1_2 &lt;= init_priv_l1_2)



            self.add_constraint(slack_left &gt;= 0)

            self.add_constraint(slack_right &gt;= 0)

            self.add_constraint(loss &lt;= init_loss)



            self.w = w

            self.w_priv = w_priv

            self.feature_relevance = cvx.Variable(nonneg=True, name="Feature Relevance")
</code></pre>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_lupi.LUPI_Relevance_CVXProblem</li>
<li>fri.model.ordinal_regression.OrdinalRegression_Relevance_Bound</li>
<li>fri.model.base_cvxproblem.Relevance_CVXProblem</li>
<li>abc.ABC</li>
</ul>
<h4 id="static-methods_1">Static methods</h4>
<h5 id="aggregate_max_candidates">aggregate_max_candidates</h5>
<pre><code class="python3">def aggregate_max_candidates(
    max_problems_candidates
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def aggregate_max_candidates(cls, max_problems_candidates):

            vals = [candidate.solved_relevance for candidate in max_problems_candidates]

            max_value = max(vals)

            return max_value
</code></pre>
<h5 id="aggregate_min_candidates">aggregate_min_candidates</h5>
<pre><code class="python3">def aggregate_min_candidates(
    min_problems_candidates
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def aggregate_min_candidates(cls, min_problems_candidates):

            vals = [candidate.solved_relevance for candidate in min_problems_candidates]

            # We take the max of mins because we need the necessary contribution over all functions

            min_value = max(vals)

            return min_value
</code></pre>
<h5 id="generate_lower_bound_problem">generate_lower_bound_problem</h5>
<pre><code class="python3">def generate_lower_bound_problem(
    best_hyperparameters,
    init_constraints,
    best_model_state,
    data,
    di,
    preset_model,
    probeID=-1
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def generate_lower_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_lower_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign in [1, -1]:

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_LB(sign=sign)

                    problem.isLowerBound = True

                    yield problem
</code></pre>
<h5 id="generate_upper_bound_problem">generate_upper_bound_problem</h5>
<pre><code class="python3">def generate_upper_bound_problem(
    best_hyperparameters,
    init_constraints,
    best_model_state,
    data,
    di,
    preset_model,
    probeID=-1
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [0, 1]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem
</code></pre>
<h4 id="instance-variables_1">Instance variables</h4>
<pre><code class="python3">accepted_status
</code></pre>

<pre><code class="python3">constraints
</code></pre>

<pre><code class="python3">cvx_problem
</code></pre>

<pre><code class="python3">isProbe
</code></pre>

<pre><code class="python3">is_solved
</code></pre>

<pre><code class="python3">objective
</code></pre>

<pre><code class="python3">probeID
</code></pre>

<pre><code class="python3">solved_relevance
</code></pre>

<pre><code class="python3">solver_kwargs
</code></pre>

<h4 id="methods_1">Methods</h4>
<h5 id="add_constraint">add_constraint</h5>
<pre><code class="python3">def add_constraint(
    self,
    new
)
</code></pre>

<p>??? example "View Source"
            def add_constraint(self, new):</p>
<pre><code>            self._constraints.append(new)
</code></pre>
<h5 id="init_objective_lb">init_objective_LB</h5>
<pre><code class="python3">def init_objective_LB(
    self,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def init_objective_LB(self, **kwargs):</p>
<pre><code>            # We have two models basically with different indexes

            if self.isPriv:

                self._init_objective_LB_LUPI(**kwargs)

            else:

                # We call sibling class of our lupi class, which is the normal problem

                super().init_objective_LB(**kwargs)
</code></pre>
<h5 id="init_objective_ub">init_objective_UB</h5>
<pre><code class="python3">def init_objective_UB(
    self,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def init_objective_UB(self, **kwargs):</p>
<pre><code>            # We have two models basically with different indexes

            if self.isPriv:

                self._init_objective_UB_LUPI(**kwargs)

            else:

                # We call sibling class of our lupi class, which is the normal problem

                super().init_objective_UB(**kwargs)
</code></pre>
<h5 id="preprocessing_data">preprocessing_data</h5>
<pre><code class="python3">def preprocessing_data(
    self,
    data,
    best_model_state
)
</code></pre>

<p>??? example "View Source"
            def preprocessing_data(self, data, best_model_state):</p>
<pre><code>            lupi_features = best_model_state["lupi_features"]

            X_combined, y = data

            X, X_priv = split_dataset(X_combined, lupi_features)

            self.X_priv = X_priv

            super().preprocessing_data((X, y), best_model_state)



            assert lupi_features == X_priv.shape[1]

            self.d_priv = lupi_features

            # LUPI model, we need to offset the index

            self.lupi_index = self.current_feature - self.d

            if self.lupi_index &gt;= 0:

                self.isPriv = True

            else:

                self.isPriv = False
</code></pre>
<h5 id="solve">solve</h5>
<pre><code class="python3">def solve(
    self
) -&gt; object
</code></pre>

<p>??? example "View Source"
            def solve(self) -&gt; object:</p>
<pre><code>            # We init cvx problem here because pickling LP solver objects is problematic

            # by deferring it to here, worker threads do the problem building themselves and we spare the serialization

            self._cvx_problem = cvx.Problem(

                objective=self.objective, constraints=self.constraints

            )

            try:

                # print("Solve", self)

                self._cvx_problem.solve(**self.solver_kwargs)

            except SolverError:

                # We ignore Solver Errors, which are common with our framework:

                # We solve multiple problems per bound and choose a feasible solution later (see '_create_interval')

                pass



            self._solver_status = self._cvx_problem.status

            # self._cvx_problem = None

            return self
</code></pre>
<h3 id="lupi_ordinalregression_svm">LUPI_OrdinalRegression_SVM</h3>
<pre><code class="python3">class LUPI_OrdinalRegression_SVM(
    **parameters
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_OrdinalRegression_SVM(LUPI_InitModel):</p>
<pre><code>        @classmethod

        def hyperparameter(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]



        def fit(self, X_combined, y, lupi_features=None):

            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape

            self.classes_ = np.unique(y)



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            get_original_bin_name, n_bins = get_bin_mapping(y)

            n_boundaries = n_bins - 1



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b_s = cvx.Variable(shape=(n_boundaries), name="bias")



            w_priv = cvx.Variable(shape=(self.lupi_features, 2), name="w_priv")

            d_priv = cvx.Variable(shape=(2), name="bias_priv")



            slack_left = cvx.Variable(shape=(n), name="slack_left")

            slack_right = cvx.Variable(shape=(n), name="slack_right")



            def priv_function(bin, sign):

                indices = np.where(y == get_original_bin_name[bin])

                return X_priv[indices] * w_priv[:, sign] + d_priv[sign]



            # L1 norm regularization of both functions with 1 scaling constant

            priv_l1_1 = cvx.norm(w_priv[:, 0], 1)

            priv_l1_2 = cvx.norm(w_priv[:, 1], 1)

            w_priv_l1 = priv_l1_1 + priv_l1_2

            w_l1 = cvx.norm(w, 1)

            weight_regularization = 0.5 * (w_l1 + scaling_lupi_w * w_priv_l1)



            constraints = []

            loss = 0



            for left_bin in range(0, n_bins - 1):

                indices = np.where(y == get_original_bin_name[left_bin])

                constraints.append(

                    X[indices] * w - b_s[left_bin] - slack_left[indices]

                    &lt;= -1 + priv_function(left_bin, 0)

                )

                constraints.append(priv_function(left_bin, 0) &gt;= 0)

                loss += cvx.sum(priv_function(left_bin, 0))



            # Add constraints for slack into right neighboring bins

            for right_bin in range(1, n_bins):

                indices = np.where(y == get_original_bin_name[right_bin])

                constraints.append(

                    X[indices] * w - b_s[right_bin - 1] - slack_right[indices]

                    &gt;= +1 - priv_function(right_bin, 1)

                )

                constraints.append(priv_function(right_bin, 1) &gt;= 0)

                loss += cvx.sum(priv_function(right_bin, 1))



            for i_boundary in range(0, n_boundaries - 1):

                constraints.append(b_s[i_boundary] &lt;= b_s[i_boundary + 1])



            constraints.append(slack_left &gt;= 0)

            constraints.append(slack_right &gt;= 0)

            loss = scaling_lupi_loss * loss + cvx.sum(slack_left + slack_right)



            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            w = w.value

            b_s = b_s.value

            self.model_state = {

                "w": w,

                "b_s": b_s,

                "w_priv": w_priv.value,

                "d_priv": d_priv.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else

                "bin_boundaries": n_boundaries,

            }



            self.constraints = {

                "loss": loss.value,

                "w_l1": w_l1.value,

                "w_priv_l1": w_priv_l1.value,

                "priv_l1_1": priv_l1_1.value,

                "priv_l1_2": priv_l1_2.value,

            }

            return self



        def predict(self, X):



            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b_s = self.model_state["b_s"]



            scores = np.dot(X, w.T)[np.newaxis]

            bin_thresholds = np.append(b_s, np.inf)



            # If thresholds are smaller than score the value belongs to the bigger bin

            # after subtracting we check for positive elements

            indices = np.sum(scores.T - bin_thresholds &gt;= 0, -1)

            return self.classes_[indices]



        def score(self, X, y, error_type="mmae", return_error=False, **kwargs):



            X, y = check_X_y(X, y)



            prediction = self.predict(X)

            score = ordinal_scores(y, prediction, error_type, return_error=return_error)



            return score



        def make_scorer(self):

            # Use multiple scores for ordinal regression

            mze = make_scorer(ordinal_scores, error_type="mze")

            mae = make_scorer(ordinal_scores, error_type="mae")

            mmae = make_scorer(ordinal_scores, error_type="mmae")

            scorer = {"mze": mze, "mae": mae, "mmae": mmae}

            return scorer, "mmae"
</code></pre>
<hr />
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_initmodel.LUPI_InitModel</li>
<li>fri.model.base_initmodel.InitModel</li>
<li>abc.ABC</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h4 id="static-methods_2">Static methods</h4>
<h5 id="hyperparameter">hyperparameter</h5>
<pre><code class="python3">def hyperparameter(

)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def hyperparameter(cls):

            return ["C", "scaling_lupi_w", "scaling_lupi_loss"]
</code></pre>
<h4 id="instance-variables_2">Instance variables</h4>
<pre><code class="python3">L1_factor
</code></pre>

<pre><code class="python3">L1_factor_priv
</code></pre>

<pre><code class="python3">constraints
</code></pre>

<pre><code class="python3">model_state
</code></pre>

<pre><code class="python3">solver_params
</code></pre>

<h4 id="methods_2">Methods</h4>
<h5 id="fit">fit</h5>
<pre><code class="python3">def fit(
    self,
    X_combined,
    y,
    lupi_features=None
)
</code></pre>

<h2 id="parameters_1">Parameters</h2>
<p>lupi_features : int
    Number of features in dataset which are considered privileged information (PI).
    PI features are expected to be the last features in the dataset.</p>
<p>??? example "View Source"
            def fit(self, X_combined, y, lupi_features=None):</p>
<pre><code>            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape

            self.classes_ = np.unique(y)



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            get_original_bin_name, n_bins = get_bin_mapping(y)

            n_boundaries = n_bins - 1



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b_s = cvx.Variable(shape=(n_boundaries), name="bias")



            w_priv = cvx.Variable(shape=(self.lupi_features, 2), name="w_priv")

            d_priv = cvx.Variable(shape=(2), name="bias_priv")



            slack_left = cvx.Variable(shape=(n), name="slack_left")

            slack_right = cvx.Variable(shape=(n), name="slack_right")



            def priv_function(bin, sign):

                indices = np.where(y == get_original_bin_name[bin])

                return X_priv[indices] * w_priv[:, sign] + d_priv[sign]



            # L1 norm regularization of both functions with 1 scaling constant

            priv_l1_1 = cvx.norm(w_priv[:, 0], 1)

            priv_l1_2 = cvx.norm(w_priv[:, 1], 1)

            w_priv_l1 = priv_l1_1 + priv_l1_2

            w_l1 = cvx.norm(w, 1)

            weight_regularization = 0.5 * (w_l1 + scaling_lupi_w * w_priv_l1)



            constraints = []

            loss = 0



            for left_bin in range(0, n_bins - 1):

                indices = np.where(y == get_original_bin_name[left_bin])

                constraints.append(

                    X[indices] * w - b_s[left_bin] - slack_left[indices]

                    &lt;= -1 + priv_function(left_bin, 0)

                )

                constraints.append(priv_function(left_bin, 0) &gt;= 0)

                loss += cvx.sum(priv_function(left_bin, 0))



            # Add constraints for slack into right neighboring bins

            for right_bin in range(1, n_bins):

                indices = np.where(y == get_original_bin_name[right_bin])

                constraints.append(

                    X[indices] * w - b_s[right_bin - 1] - slack_right[indices]

                    &gt;= +1 - priv_function(right_bin, 1)

                )

                constraints.append(priv_function(right_bin, 1) &gt;= 0)

                loss += cvx.sum(priv_function(right_bin, 1))



            for i_boundary in range(0, n_boundaries - 1):

                constraints.append(b_s[i_boundary] &lt;= b_s[i_boundary + 1])



            constraints.append(slack_left &gt;= 0)

            constraints.append(slack_right &gt;= 0)

            loss = scaling_lupi_loss * loss + cvx.sum(slack_left + slack_right)



            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            w = w.value

            b_s = b_s.value

            self.model_state = {

                "w": w,

                "b_s": b_s,

                "w_priv": w_priv.value,

                "d_priv": d_priv.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else

                "bin_boundaries": n_boundaries,

            }



            self.constraints = {

                "loss": loss.value,

                "w_l1": w_l1.value,

                "w_priv_l1": w_priv_l1.value,

                "priv_l1_1": priv_l1_1.value,

                "priv_l1_2": priv_l1_2.value,

            }

            return self
</code></pre>
<h5 id="get_params">get_params</h5>
<pre><code class="python3">def get_params(
    self,
    deep=True
)
</code></pre>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_2">Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2 id="returns">Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p>
<p>??? example "View Source"
            def get_params(self, deep=True):</p>
<pre><code>            return self.hyperparam
</code></pre>
<h5 id="make_scorer">make_scorer</h5>
<pre><code class="python3">def make_scorer(
    self
)
</code></pre>

<p>??? example "View Source"
            def make_scorer(self):</p>
<pre><code>            # Use multiple scores for ordinal regression

            mze = make_scorer(ordinal_scores, error_type="mze")

            mae = make_scorer(ordinal_scores, error_type="mae")

            mmae = make_scorer(ordinal_scores, error_type="mmae")

            scorer = {"mze": mze, "mae": mae, "mmae": mmae}

            return scorer, "mmae"
</code></pre>
<h5 id="predict">predict</h5>
<pre><code class="python3">def predict(
    self,
    X
)
</code></pre>

<p>??? example "View Source"
            def predict(self, X):</p>
<pre><code>            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b_s = self.model_state["b_s"]



            scores = np.dot(X, w.T)[np.newaxis]

            bin_thresholds = np.append(b_s, np.inf)



            # If thresholds are smaller than score the value belongs to the bigger bin

            # after subtracting we check for positive elements

            indices = np.sum(scores.T - bin_thresholds &gt;= 0, -1)

            return self.classes_[indices]
</code></pre>
<h5 id="score">score</h5>
<pre><code class="python3">def score(
    self,
    X,
    y,
    error_type='mmae',
    return_error=False,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def score(self, X, y, error_type="mmae", return_error=False, **kwargs):</p>
<pre><code>            X, y = check_X_y(X, y)



            prediction = self.predict(X)

            score = ordinal_scores(y, prediction, error_type, return_error=return_error)



            return score
</code></pre>
<h5 id="set_params">set_params</h5>
<pre><code class="python3">def set_params(
    self,
    **params
)
</code></pre>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="returns_1">Returns</h2>
<p>self</p>
<p>??? example "View Source"
            def set_params(self, **params):</p>
<pre><code>            for p, value in params.items():

                self.hyperparam[p] = value

            return self
</code></pre>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../lupi_classification/" title="Lupi Classification" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Lupi Classification
              </span>
            </div>
          </a>
        
        
          <a href="../lupi_regression/" title="Lupi Regression" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Lupi Regression
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.c648116f.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
    
  </body>
</html>