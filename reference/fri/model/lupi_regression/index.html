



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../../docs/favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.2">
    
    
      
        <title>Lupi Regression - fri</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.30686662.css">
      
      
    
    
      <script src="../../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#module-frimodellupi_regression" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../.." title="fri" class="md-header-nav__button md-logo">
          
            <img src="../../../../docs/logo.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              fri
            </span>
            <span class="md-header-nav__topic">
              
                Lupi Regression
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/lpfann/fri/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    lpfann/fri
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../.." title="fri" class="md-nav__button md-logo">
      
        <img src="../../../../docs/logo.png" width="48" height="48">
      
    </a>
    fri
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/lpfann/fri/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    lpfann/fri
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/Guide/" title="Guide" class="md-nav__link">
      Guide
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/background/" title="Background" class="md-nav__link">
      Background
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/citing_FRI/" title="Citing Fri" class="md-nav__link">
      Citing Fri
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Reference
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1" checked>
    
    <label class="md-nav__link" for="nav-5-1">
      Fri
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        Fri
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../compute/" title="Compute" class="md-nav__link">
      Compute
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../main/" title="Main" class="md-nav__link">
      Main
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../parameter_searcher/" title="Parameter Searcher" class="md-nav__link">
      Parameter Searcher
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../plot/" title="Plot" class="md-nav__link">
      Plot
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-7" type="checkbox" id="nav-5-1-7" checked>
    
    <label class="md-nav__link" for="nav-5-1-7">
      Model
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-7">
        Model
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../base_cvxproblem/" title="Base Cvxproblem" class="md-nav__link">
      Base Cvxproblem
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_initmodel/" title="Base Initmodel" class="md-nav__link">
      Base Initmodel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_lupi/" title="Base Lupi" class="md-nav__link">
      Base Lupi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../base_type/" title="Base Type" class="md-nav__link">
      Base Type
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../classification/" title="Classification" class="md-nav__link">
      Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lupi_classification/" title="Lupi Classification" class="md-nav__link">
      Lupi Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lupi_ordinal_regression/" title="Lupi Ordinal Regression" class="md-nav__link">
      Lupi Ordinal Regression
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Lupi Regression
      </label>
    
    <a href="./" title="Lupi Regression" class="md-nav__link md-nav__link--active">
      Lupi Regression
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lupi_regression" class="md-nav__link">
    LUPI_Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_all_parameters" class="md-nav__link">
    get_all_parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_all_relax_factors" class="md-nav__link">
    get_all_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_parameter" class="md-nav__link">
    get_chosen_parameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_relax_factors" class="md-nav__link">
    get_chosen_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_relaxed_constraints" class="md-nav__link">
    get_relaxed_constraints
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postprocessing" class="md-nav__link">
    postprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_constraint" class="md-nav__link">
    relax_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_factors" class="md-nav__link">
    relax_factors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_regression_relevance_bound" class="md-nav__link">
    LUPI_Regression_Relevance_Bound
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aggregate_max_candidates" class="md-nav__link">
    aggregate_max_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregate_min_candidates" class="md-nav__link">
    aggregate_min_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_lower_bound_problem" class="md-nav__link">
    generate_lower_bound_problem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_upper_bound_problem" class="md-nav__link">
    generate_upper_bound_problem
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_constraint" class="md-nav__link">
    add_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_lb" class="md-nav__link">
    init_objective_LB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_ub" class="md-nav__link">
    init_objective_UB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing_data" class="md-nav__link">
    preprocessing_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solve" class="md-nav__link">
    solve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_regression_svm" class="md-nav__link">
    LUPI_Regression_SVM
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameter" class="md-nav__link">
    hyperparameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../ordinal_regression/" title="Ordinal Regression" class="md-nav__link">
      Ordinal Regression
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../regression/" title="Regression" class="md-nav__link">
      Regression
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-8" type="checkbox" id="nav-5-1-8">
    
    <label class="md-nav__link" for="nav-5-1-8">
      Toydata
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-8">
        Toydata
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/gen_data/" title="Gen Data" class="md-nav__link">
      Gen Data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/gen_lupi/" title="Gen Lupi" class="md-nav__link">
      Gen Lupi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../toydata/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lupi_regression" class="md-nav__link">
    LUPI_Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_all_parameters" class="md-nav__link">
    get_all_parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_all_relax_factors" class="md-nav__link">
    get_all_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_parameter" class="md-nav__link">
    get_chosen_parameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_chosen_relax_factors" class="md-nav__link">
    get_chosen_relax_factors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_relaxed_constraints" class="md-nav__link">
    get_relaxed_constraints
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postprocessing" class="md-nav__link">
    postprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    preprocessing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_constraint" class="md-nav__link">
    relax_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relax_factors" class="md-nav__link">
    relax_factors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_regression_relevance_bound" class="md-nav__link">
    LUPI_Regression_Relevance_Bound
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aggregate_max_candidates" class="md-nav__link">
    aggregate_max_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregate_min_candidates" class="md-nav__link">
    aggregate_min_candidates
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_lower_bound_problem" class="md-nav__link">
    generate_lower_bound_problem
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_upper_bound_problem" class="md-nav__link">
    generate_upper_bound_problem
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_constraint" class="md-nav__link">
    add_constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_lb" class="md-nav__link">
    init_objective_LB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#init_objective_ub" class="md-nav__link">
    init_objective_UB
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing_data" class="md-nav__link">
    preprocessing_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solve" class="md-nav__link">
    solve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lupi_regression_svm" class="md-nav__link">
    LUPI_Regression_SVM
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameter" class="md-nav__link">
    hyperparameter
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make_scorer" class="md-nav__link">
    make_scorer
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_params" class="md-nav__link">
    get_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#predict" class="md-nav__link">
    predict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#score" class="md-nav__link">
    score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_params" class="md-nav__link">
    set_params
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/lpfann/fri/edit/master/docs/reference/fri/model/lupi_regression.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="module-frimodellupi_regression">Module fri.model.lupi_regression</h1>
<p>??? example "View Source"
        from itertools import product</p>
<pre><code>    import cvxpy as cvx

    import numpy as np

    from sklearn.metrics import r2_score

    from sklearn.metrics.regression import _check_reg_targets

    from sklearn.utils import check_X_y



    from fri.model.base_lupi import (

        LUPI_Relevance_CVXProblem,

        split_dataset,

        is_lupi_feature,

    )

    from fri.model.regression import Regression_Relevance_Bound

    from .base_initmodel import LUPI_InitModel

    from .base_type import ProblemType





    class LUPI_Regression(ProblemType):

        def __init__(self, **kwargs):

            super().__init__(**kwargs)

            self._lupi_features = None



        @property

        def lupi_features(self):

            return self._lupi_features



        @classmethod

        def parameters(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]



        @property

        def get_initmodel_template(cls):

            return LUPI_Regression_SVM



        @property

        def get_cvxproblem_template(cls):

            return LUPI_Regression_Relevance_Bound



        def relax_factors(cls):

            return ["loss_slack", "w_l1_slack"]



        def preprocessing(self, data, lupi_features=None):

            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)



            return X, y





    class LUPI_Regression_SVM(LUPI_InitModel):

        @classmethod

        def hyperparameter(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]



        def fit(self, X_combined, y, lupi_features=None):

            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            epsilon = self.hyperparam["epsilon"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b = cvx.Variable(name="bias")

            w_priv_pos = cvx.Variable(lupi_features, name="w_priv_pos")

            b_priv_pos = cvx.Variable(name="bias_priv_pos")

            w_priv_neg = cvx.Variable(lupi_features, name="w_priv_neg")

            b_priv_neg = cvx.Variable(name="bias_priv_neg")

            slack = cvx.Variable(shape=(n), name="slack")



            # Define functions for better readability

            priv_function_pos = X_priv * w_priv_pos + b_priv_pos

            priv_function_neg = X_priv * w_priv_neg + b_priv_neg



            # Combined loss of lupi function and normal slacks, scaled by two constants

            priv_loss_pos = cvx.sum(priv_function_pos)

            priv_loss_neg = cvx.sum(priv_function_neg)

            priv_loss = priv_loss_pos + priv_loss_neg

            slack_loss = cvx.sum(slack)

            loss = scaling_lupi_loss * priv_loss + slack_loss



            # L1 norm regularization of both functions with 1 scaling constant

            weight_regularization = 0.5 * (

                cvx.norm(w, 1)

                + scaling_lupi_w

                * (0.5 * cvx.norm(w_priv_pos, 1) + 0.5 * cvx.norm(w_priv_neg, 1))

            )



            constraints = [

                y - X * w - b &lt;= epsilon + priv_function_pos + slack,

                X * w + b - y &lt;= epsilon + priv_function_neg + slack,

                priv_function_pos &gt;= 0,

                priv_function_neg &gt;= 0,

                # priv_loss_pos &gt;= 0,

                # priv_loss_neg &gt;= 0,

                # slack_loss &gt;= 0,

                slack &gt;= 0,

                # loss &gt;= 0,

            ]

            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            self.model_state = {

                "signs_pos": priv_function_pos.value &gt; 0,

                "signs_neg": priv_function_neg.value &gt; 0,

                "w": w.value,

                "w_priv_pos": w_priv_pos.value,

                "w_priv_neg": w_priv_neg.value,

                "b": b.value,

                "b_priv_pos": b_priv_pos.value,

                "b_priv_neg": b_priv_neg.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else,

            }

            w_l1 = np.linalg.norm(w.value, ord=1)

            w_priv_pos_l1 = np.linalg.norm(w_priv_pos.value, ord=1)

            w_priv_neg_l1 = np.linalg.norm(w_priv_neg.value, ord=1)

            # We take the mean to combine all submodels (for priv) into a single normalization factor

            w_priv_l1 = w_priv_pos_l1 + w_priv_neg_l1

            self.constraints = {

                "priv_loss": priv_loss.value,

                "scaling_lupi_loss": scaling_lupi_loss,

                # "loss_slack": slack_loss.value,

                "loss": loss.value,

                "w_l1": w_l1,

                "w_priv_l1": w_priv_l1,

                "w_priv_pos_l1": w_priv_pos_l1,

                "w_priv_neg_l1": w_priv_neg_l1,

            }

            return self



        @property

        def solver_params(cls):

            return {"solver": "ECOS", "verbose": False}



        def predict(self, X):

            """

            Method to predict points using svm classification rule.

            We use both normal and priv. features.

            This function is mainly used for CV purposes to find the best parameters according to score.



            Parameters

            ----------

            X : numpy.ndarray

            """

            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b = self.model_state["b"]



            y = np.dot(X, w) + b



            return y



        def score(self, X, y, **kwargs):

            prediction = self.predict(X)

            _check_reg_targets(y, prediction, None)



            score = r2_score(y, prediction)

            return score





    class LUPI_Regression_Relevance_Bound(

        LUPI_Relevance_CVXProblem, Regression_Relevance_Bound

    ):

        @classmethod

        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [True, False]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem



        def _init_objective_LB_LUPI(self, **kwargs):

            self.add_constraint(

                cvx.abs(self.w_priv_pos[self.lupi_index]) &lt;= self.feature_relevance

            )

            self.add_constraint(

                cvx.abs(self.w_priv_neg[self.lupi_index]) &lt;= self.feature_relevance

            )



            self._objective = cvx.Minimize(self.feature_relevance)



        def _init_objective_UB_LUPI(self, pos=None, sign=None, **kwargs):

            if pos:

                self.add_constraint(

                    self.feature_relevance &lt;= sign * self.w_priv_pos[self.lupi_index]

                )

            else:

                self.add_constraint(

                    self.feature_relevance &lt;= sign * self.w_priv_neg[self.lupi_index]

                )



            self._objective = cvx.Maximize(self.feature_relevance)



        def _init_constraints(self, parameters, init_model_constraints):

            # Upper constraints from best initial model

            l1_w = init_model_constraints["w_l1"]

            self.l1_priv_w_pos = init_model_constraints["w_priv_pos_l1"]

            self.l1_priv_w_neg = init_model_constraints["w_priv_neg_l1"]

            init_loss = init_model_constraints["loss"]

            epsilon = parameters["epsilon"]

            scaling_lupi_loss = init_model_constraints["scaling_lupi_loss"]



            # New Variables

            w = cvx.Variable(shape=(self.d), name="w")

            b = cvx.Variable(name="b")

            w_priv_pos = cvx.Variable(self.d_priv, name="w_priv_pos")

            b_priv_pos = cvx.Variable(name="bias_priv_pos")

            w_priv_neg = cvx.Variable(self.d_priv, name="w_priv_neg")

            b_priv_neg = cvx.Variable(name="bias_priv_neg")

            slack = cvx.Variable(shape=(self.n))



            priv_function_pos = self.X_priv * w_priv_pos + b_priv_pos

            priv_function_neg = self.X_priv * w_priv_neg + b_priv_neg

            priv_loss = cvx.sum(priv_function_pos + priv_function_neg)

            loss = priv_loss + cvx.sum(slack)

            weight_norm = cvx.norm(w, 1)

            self.weight_norm_priv_pos = cvx.norm(w_priv_pos, 1)

            self.weight_norm_priv_neg = cvx.norm(w_priv_neg, 1)



            self.add_constraint(

                self.y - self.X * w - b &lt;= epsilon + priv_function_pos + slack

            )

            self.add_constraint(

                self.X * w + b - self.y &lt;= epsilon + priv_function_neg + slack

            )

            self.add_constraint(priv_function_pos &gt;= 0)

            self.add_constraint(priv_function_neg &gt;= 0)

            self.add_constraint(loss &lt;= init_loss)

            self.add_constraint(slack &gt;= 0)

            sum_norms = weight_norm + self.weight_norm_priv_pos + self.weight_norm_priv_neg

            self.add_constraint(sum_norms &lt;= l1_w)

            # self.add_constraint(self.weight_norm_priv_pos &lt;= self.l1_priv_w_pos)

            # self.add_constraint(self.weight_norm_priv_neg &lt;= self.l1_priv_w_neg)



            # Save values for object use later

            self.w = w

            self.w_priv_pos = w_priv_pos

            self.w_priv_neg = w_priv_neg

            self.feature_relevance = cvx.Variable(nonneg=True, name="Feature Relevance")
</code></pre>
<h2 id="classes">Classes</h2>
<h3 id="lupi_regression">LUPI_Regression</h3>
<pre><code class="python3">class LUPI_Regression(
    **kwargs
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_Regression(ProblemType):</p>
<pre><code>        def __init__(self, **kwargs):

            super().__init__(**kwargs)

            self._lupi_features = None



        @property

        def lupi_features(self):

            return self._lupi_features



        @classmethod

        def parameters(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]



        @property

        def get_initmodel_template(cls):

            return LUPI_Regression_SVM



        @property

        def get_cvxproblem_template(cls):

            return LUPI_Regression_Relevance_Bound



        def relax_factors(cls):

            return ["loss_slack", "w_l1_slack"]



        def preprocessing(self, data, lupi_features=None):

            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)



            return X, y
</code></pre>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_type.ProblemType</li>
<li>abc.ABC</li>
</ul>
<h4 id="static-methods">Static methods</h4>
<h5 id="parameters">parameters</h5>
<pre><code class="python3">def parameters(

)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def parameters(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]
</code></pre>
<h4 id="instance-variables">Instance variables</h4>
<pre><code class="python3">get_cvxproblem_template
</code></pre>

<pre><code class="python3">get_initmodel_template
</code></pre>

<pre><code class="python3">lupi_features
</code></pre>

<h4 id="methods">Methods</h4>
<h5 id="get_all_parameters">get_all_parameters</h5>
<pre><code class="python3">def get_all_parameters(
    self
)
</code></pre>

<p>??? example "View Source"
            def get_all_parameters(self):</p>
<pre><code>            return {p: self.get_chosen_parameter(p) for p in self.parameters()}
</code></pre>
<h5 id="get_all_relax_factors">get_all_relax_factors</h5>
<pre><code class="python3">def get_all_relax_factors(
    self
)
</code></pre>

<p>??? example "View Source"
            def get_all_relax_factors(self):</p>
<pre><code>            return {p: self.get_chosen_relax_factors(p) for p in self.relax_factors()}
</code></pre>
<h5 id="get_chosen_parameter">get_chosen_parameter</h5>
<pre><code class="python3">def get_chosen_parameter(
    self,
    p
)
</code></pre>

<p>??? example "View Source"
            def get_chosen_parameter(self, p):</p>
<pre><code>            try:

                return [

                    self.chosen_parameters_[p]

                ]  # We return list for param search function

            except:

                # # TODO: rewrite the parameter logic

                # # TODO: move this to subclass

                if p == "scaling_lupi_w":

                    # return [0.1, 1, 10, 100, 1000]

                    return scipy.stats.reciprocal(a=1e-15, b=1e10)

                # if p == "scaling_lupi_loss":

                #    # value 0&gt;p&lt;1 causes standard svm solution

                #    # p&gt;1 encourages usage of lupi function

                #    return scipy.stats.reciprocal(a=1e-15, b=1e15)

                if p == "C":

                    return scipy.stats.reciprocal(a=1e-5, b=1e5)

                if p == "epsilon":

                    return [0, 0.001, 0.01, 0.1, 1, 10, 100]

                else:

                    return scipy.stats.reciprocal(a=1e-10, b=1e10)
</code></pre>
<h5 id="get_chosen_relax_factors">get_chosen_relax_factors</h5>
<pre><code class="python3">def get_chosen_relax_factors(
    self,
    p
)
</code></pre>

<p>??? example "View Source"
            def get_chosen_relax_factors(self, p):</p>
<pre><code>            try:

                factor = self.relax_factors_[p]

            except KeyError:

                try:

                    factor = self.relax_factors_[p + "_slack"]

                except KeyError:

                    factor = 0.1

            if factor &lt; 0:

                raise ValueError("Slack Factor multiplier is positive!")

            return factor
</code></pre>
<h5 id="get_relaxed_constraints">get_relaxed_constraints</h5>
<pre><code class="python3">def get_relaxed_constraints(
    self,
    constraints
)
</code></pre>

<p>??? example "View Source"
            def get_relaxed_constraints(self, constraints):</p>
<pre><code>            return {c: self.relax_constraint(c, v) for c, v in constraints.items()}
</code></pre>
<h5 id="postprocessing">postprocessing</h5>
<pre><code class="python3">def postprocessing(
    self,
    bounds
)
</code></pre>

<p>??? example "View Source"
            def postprocessing(self, bounds):</p>
<pre><code>            return bounds
</code></pre>
<h5 id="preprocessing">preprocessing</h5>
<pre><code class="python3">def preprocessing(
    self,
    data,
    lupi_features=None
)
</code></pre>

<p>??? example "View Source"
            def preprocessing(self, data, lupi_features=None):</p>
<pre><code>            X, y = data

            d = X.shape[1]



            if lupi_features is None:

                raise ValueError("Argument 'lupi_features' missing in fit() call.")

            if not isinstance(lupi_features, int):

                raise ValueError("Argument 'lupi_features' is not type int.")

            if not 0 &lt; lupi_features &lt; d:

                raise ValueError(

                    "Argument 'lupi_features' looks wrong. We need at least 1 priviliged feature (&gt;0) or at least one normal feature."

                )



            self._lupi_features = lupi_features



            # Check that X and y have correct shape

            X, y = check_X_y(X, y)



            return X, y
</code></pre>
<h5 id="relax_constraint">relax_constraint</h5>
<pre><code class="python3">def relax_constraint(
    self,
    key,
    value
)
</code></pre>

<p>??? example "View Source"
            def relax_constraint(self, key, value):</p>
<pre><code>            return value * (1 + self.get_chosen_relax_factors(key))
</code></pre>
<h5 id="relax_factors">relax_factors</h5>
<pre><code class="python3">def relax_factors(
    cls
)
</code></pre>

<p>??? example "View Source"
            def relax_factors(cls):</p>
<pre><code>            return ["loss_slack", "w_l1_slack"]
</code></pre>
<h3 id="lupi_regression_relevance_bound">LUPI_Regression_Relevance_Bound</h3>
<pre><code class="python3">class LUPI_Regression_Relevance_Bound(
    current_feature:int,
    data:tuple,
    hyperparameters,
    best_model_constraints,
    preset_model=None,
    best_model_state=None,
    probeID=-1
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_Regression_Relevance_Bound(</p>
<pre><code>        LUPI_Relevance_CVXProblem, Regression_Relevance_Bound

    ):

        @classmethod

        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [True, False]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem



        def _init_objective_LB_LUPI(self, **kwargs):

            self.add_constraint(

                cvx.abs(self.w_priv_pos[self.lupi_index]) &lt;= self.feature_relevance

            )

            self.add_constraint(

                cvx.abs(self.w_priv_neg[self.lupi_index]) &lt;= self.feature_relevance

            )



            self._objective = cvx.Minimize(self.feature_relevance)



        def _init_objective_UB_LUPI(self, pos=None, sign=None, **kwargs):

            if pos:

                self.add_constraint(

                    self.feature_relevance &lt;= sign * self.w_priv_pos[self.lupi_index]

                )

            else:

                self.add_constraint(

                    self.feature_relevance &lt;= sign * self.w_priv_neg[self.lupi_index]

                )



            self._objective = cvx.Maximize(self.feature_relevance)



        def _init_constraints(self, parameters, init_model_constraints):

            # Upper constraints from best initial model

            l1_w = init_model_constraints["w_l1"]

            self.l1_priv_w_pos = init_model_constraints["w_priv_pos_l1"]

            self.l1_priv_w_neg = init_model_constraints["w_priv_neg_l1"]

            init_loss = init_model_constraints["loss"]

            epsilon = parameters["epsilon"]

            scaling_lupi_loss = init_model_constraints["scaling_lupi_loss"]



            # New Variables

            w = cvx.Variable(shape=(self.d), name="w")

            b = cvx.Variable(name="b")

            w_priv_pos = cvx.Variable(self.d_priv, name="w_priv_pos")

            b_priv_pos = cvx.Variable(name="bias_priv_pos")

            w_priv_neg = cvx.Variable(self.d_priv, name="w_priv_neg")

            b_priv_neg = cvx.Variable(name="bias_priv_neg")

            slack = cvx.Variable(shape=(self.n))



            priv_function_pos = self.X_priv * w_priv_pos + b_priv_pos

            priv_function_neg = self.X_priv * w_priv_neg + b_priv_neg

            priv_loss = cvx.sum(priv_function_pos + priv_function_neg)

            loss = priv_loss + cvx.sum(slack)

            weight_norm = cvx.norm(w, 1)

            self.weight_norm_priv_pos = cvx.norm(w_priv_pos, 1)

            self.weight_norm_priv_neg = cvx.norm(w_priv_neg, 1)



            self.add_constraint(

                self.y - self.X * w - b &lt;= epsilon + priv_function_pos + slack

            )

            self.add_constraint(

                self.X * w + b - self.y &lt;= epsilon + priv_function_neg + slack

            )

            self.add_constraint(priv_function_pos &gt;= 0)

            self.add_constraint(priv_function_neg &gt;= 0)

            self.add_constraint(loss &lt;= init_loss)

            self.add_constraint(slack &gt;= 0)

            sum_norms = weight_norm + self.weight_norm_priv_pos + self.weight_norm_priv_neg

            self.add_constraint(sum_norms &lt;= l1_w)

            # self.add_constraint(self.weight_norm_priv_pos &lt;= self.l1_priv_w_pos)

            # self.add_constraint(self.weight_norm_priv_neg &lt;= self.l1_priv_w_neg)



            # Save values for object use later

            self.w = w

            self.w_priv_pos = w_priv_pos

            self.w_priv_neg = w_priv_neg

            self.feature_relevance = cvx.Variable(nonneg=True, name="Feature Relevance")
</code></pre>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_lupi.LUPI_Relevance_CVXProblem</li>
<li>fri.model.regression.Regression_Relevance_Bound</li>
<li>fri.model.base_cvxproblem.Relevance_CVXProblem</li>
<li>abc.ABC</li>
</ul>
<h4 id="static-methods_1">Static methods</h4>
<h5 id="aggregate_max_candidates">aggregate_max_candidates</h5>
<pre><code class="python3">def aggregate_max_candidates(
    max_problems_candidates
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def aggregate_max_candidates(cls, max_problems_candidates):

            vals = [candidate.solved_relevance for candidate in max_problems_candidates]

            max_value = max(vals)

            return max_value
</code></pre>
<h5 id="aggregate_min_candidates">aggregate_min_candidates</h5>
<pre><code class="python3">def aggregate_min_candidates(
    min_problems_candidates
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def aggregate_min_candidates(cls, min_problems_candidates):

            vals = [candidate.solved_relevance for candidate in min_problems_candidates]

            min_value = min(vals)

            return min_value
</code></pre>
<h5 id="generate_lower_bound_problem">generate_lower_bound_problem</h5>
<pre><code class="python3">def generate_lower_bound_problem(
    best_hyperparameters,
    init_constraints,
    best_model_state,
    data,
    di,
    preset_model,
    probeID=-1
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def generate_lower_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            problem = cls(

                di,

                data,

                best_hyperparameters,

                init_constraints,

                preset_model=preset_model,

                best_model_state=best_model_state,

                probeID=probeID,

            )

            problem.init_objective_LB()

            problem.isLowerBound = True

            yield problem
</code></pre>
<h5 id="generate_upper_bound_problem">generate_upper_bound_problem</h5>
<pre><code class="python3">def generate_upper_bound_problem(
    best_hyperparameters,
    init_constraints,
    best_model_state,
    data,
    di,
    preset_model,
    probeID=-1
)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def generate_upper_bound_problem(

            cls,

            best_hyperparameters,

            init_constraints,

            best_model_state,

            data,

            di,

            preset_model,

            probeID=-1,

        ):

            is_priv = is_lupi_feature(

                di, data, best_model_state

            )  # Is it a lupi feature where we need additional candidate problems?



            if not is_priv:

                yield from super().generate_upper_bound_problem(

                    best_hyperparameters,

                    init_constraints,

                    best_model_state,

                    data,

                    di,

                    preset_model,

                    probeID=probeID,

                )

            else:

                for sign, pos in product([1, -1], [True, False]):

                    problem = cls(

                        di,

                        data,

                        best_hyperparameters,

                        init_constraints,

                        preset_model=preset_model,

                        best_model_state=best_model_state,

                        probeID=probeID,

                    )

                    problem.init_objective_UB(sign=sign, pos=pos)

                    yield problem
</code></pre>
<h4 id="instance-variables_1">Instance variables</h4>
<pre><code class="python3">accepted_status
</code></pre>

<pre><code class="python3">constraints
</code></pre>

<pre><code class="python3">cvx_problem
</code></pre>

<pre><code class="python3">isProbe
</code></pre>

<pre><code class="python3">is_solved
</code></pre>

<pre><code class="python3">objective
</code></pre>

<pre><code class="python3">probeID
</code></pre>

<pre><code class="python3">solved_relevance
</code></pre>

<pre><code class="python3">solver_kwargs
</code></pre>

<h4 id="methods_1">Methods</h4>
<h5 id="add_constraint">add_constraint</h5>
<pre><code class="python3">def add_constraint(
    self,
    new
)
</code></pre>

<p>??? example "View Source"
            def add_constraint(self, new):</p>
<pre><code>            self._constraints.append(new)
</code></pre>
<h5 id="init_objective_lb">init_objective_LB</h5>
<pre><code class="python3">def init_objective_LB(
    self,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def init_objective_LB(self, **kwargs):</p>
<pre><code>            # We have two models basically with different indexes

            if self.isPriv:

                self._init_objective_LB_LUPI(**kwargs)

            else:

                # We call sibling class of our lupi class, which is the normal problem

                super().init_objective_LB(**kwargs)
</code></pre>
<h5 id="init_objective_ub">init_objective_UB</h5>
<pre><code class="python3">def init_objective_UB(
    self,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def init_objective_UB(self, **kwargs):</p>
<pre><code>            # We have two models basically with different indexes

            if self.isPriv:

                self._init_objective_UB_LUPI(**kwargs)

            else:

                # We call sibling class of our lupi class, which is the normal problem

                super().init_objective_UB(**kwargs)
</code></pre>
<h5 id="preprocessing_data">preprocessing_data</h5>
<pre><code class="python3">def preprocessing_data(
    self,
    data,
    best_model_state
)
</code></pre>

<p>??? example "View Source"
            def preprocessing_data(self, data, best_model_state):</p>
<pre><code>            lupi_features = best_model_state["lupi_features"]

            X_combined, y = data

            X, X_priv = split_dataset(X_combined, lupi_features)

            self.X_priv = X_priv

            super().preprocessing_data((X, y), best_model_state)



            assert lupi_features == X_priv.shape[1]

            self.d_priv = lupi_features

            # LUPI model, we need to offset the index

            self.lupi_index = self.current_feature - self.d

            if self.lupi_index &gt;= 0:

                self.isPriv = True

            else:

                self.isPriv = False
</code></pre>
<h5 id="solve">solve</h5>
<pre><code class="python3">def solve(
    self
) -&gt; object
</code></pre>

<p>??? example "View Source"
            def solve(self) -&gt; object:</p>
<pre><code>            # We init cvx problem here because pickling LP solver objects is problematic

            # by deferring it to here, worker threads do the problem building themselves and we spare the serialization

            self._cvx_problem = cvx.Problem(

                objective=self.objective, constraints=self.constraints

            )

            try:

                # print("Solve", self)

                self._cvx_problem.solve(**self.solver_kwargs)

            except SolverError:

                # We ignore Solver Errors, which are common with our framework:

                # We solve multiple problems per bound and choose a feasible solution later (see '_create_interval')

                pass



            self._solver_status = self._cvx_problem.status

            # self._cvx_problem = None

            return self
</code></pre>
<h3 id="lupi_regression_svm">LUPI_Regression_SVM</h3>
<pre><code class="python3">class LUPI_Regression_SVM(
    **parameters
)
</code></pre>

<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>??? example "View Source"
        class LUPI_Regression_SVM(LUPI_InitModel):</p>
<pre><code>        @classmethod

        def hyperparameter(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]



        def fit(self, X_combined, y, lupi_features=None):

            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            epsilon = self.hyperparam["epsilon"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b = cvx.Variable(name="bias")

            w_priv_pos = cvx.Variable(lupi_features, name="w_priv_pos")

            b_priv_pos = cvx.Variable(name="bias_priv_pos")

            w_priv_neg = cvx.Variable(lupi_features, name="w_priv_neg")

            b_priv_neg = cvx.Variable(name="bias_priv_neg")

            slack = cvx.Variable(shape=(n), name="slack")



            # Define functions for better readability

            priv_function_pos = X_priv * w_priv_pos + b_priv_pos

            priv_function_neg = X_priv * w_priv_neg + b_priv_neg



            # Combined loss of lupi function and normal slacks, scaled by two constants

            priv_loss_pos = cvx.sum(priv_function_pos)

            priv_loss_neg = cvx.sum(priv_function_neg)

            priv_loss = priv_loss_pos + priv_loss_neg

            slack_loss = cvx.sum(slack)

            loss = scaling_lupi_loss * priv_loss + slack_loss



            # L1 norm regularization of both functions with 1 scaling constant

            weight_regularization = 0.5 * (

                cvx.norm(w, 1)

                + scaling_lupi_w

                * (0.5 * cvx.norm(w_priv_pos, 1) + 0.5 * cvx.norm(w_priv_neg, 1))

            )



            constraints = [

                y - X * w - b &lt;= epsilon + priv_function_pos + slack,

                X * w + b - y &lt;= epsilon + priv_function_neg + slack,

                priv_function_pos &gt;= 0,

                priv_function_neg &gt;= 0,

                # priv_loss_pos &gt;= 0,

                # priv_loss_neg &gt;= 0,

                # slack_loss &gt;= 0,

                slack &gt;= 0,

                # loss &gt;= 0,

            ]

            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            self.model_state = {

                "signs_pos": priv_function_pos.value &gt; 0,

                "signs_neg": priv_function_neg.value &gt; 0,

                "w": w.value,

                "w_priv_pos": w_priv_pos.value,

                "w_priv_neg": w_priv_neg.value,

                "b": b.value,

                "b_priv_pos": b_priv_pos.value,

                "b_priv_neg": b_priv_neg.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else,

            }

            w_l1 = np.linalg.norm(w.value, ord=1)

            w_priv_pos_l1 = np.linalg.norm(w_priv_pos.value, ord=1)

            w_priv_neg_l1 = np.linalg.norm(w_priv_neg.value, ord=1)

            # We take the mean to combine all submodels (for priv) into a single normalization factor

            w_priv_l1 = w_priv_pos_l1 + w_priv_neg_l1

            self.constraints = {

                "priv_loss": priv_loss.value,

                "scaling_lupi_loss": scaling_lupi_loss,

                # "loss_slack": slack_loss.value,

                "loss": loss.value,

                "w_l1": w_l1,

                "w_priv_l1": w_priv_l1,

                "w_priv_pos_l1": w_priv_pos_l1,

                "w_priv_neg_l1": w_priv_neg_l1,

            }

            return self



        @property

        def solver_params(cls):

            return {"solver": "ECOS", "verbose": False}



        def predict(self, X):

            """

            Method to predict points using svm classification rule.

            We use both normal and priv. features.

            This function is mainly used for CV purposes to find the best parameters according to score.



            Parameters

            ----------

            X : numpy.ndarray

            """

            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b = self.model_state["b"]



            y = np.dot(X, w) + b



            return y



        def score(self, X, y, **kwargs):

            prediction = self.predict(X)

            _check_reg_targets(y, prediction, None)



            score = r2_score(y, prediction)

            return score
</code></pre>
<hr />
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>fri.model.base_initmodel.LUPI_InitModel</li>
<li>fri.model.base_initmodel.InitModel</li>
<li>abc.ABC</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h4 id="static-methods_2">Static methods</h4>
<h5 id="hyperparameter">hyperparameter</h5>
<pre><code class="python3">def hyperparameter(

)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def hyperparameter(cls):

            return ["C", "epsilon", "scaling_lupi_w", "scaling_lupi_loss"]
</code></pre>
<h5 id="make_scorer">make_scorer</h5>
<pre><code class="python3">def make_scorer(

)
</code></pre>

<p>??? example "View Source"
            @classmethod</p>
<pre><code>        def make_scorer(self):

            return None, None
</code></pre>
<h4 id="instance-variables_2">Instance variables</h4>
<pre><code class="python3">L1_factor
</code></pre>

<pre><code class="python3">L1_factor_priv
</code></pre>

<pre><code class="python3">constraints
</code></pre>

<pre><code class="python3">model_state
</code></pre>

<pre><code class="python3">solver_params
</code></pre>

<h4 id="methods_2">Methods</h4>
<h5 id="fit">fit</h5>
<pre><code class="python3">def fit(
    self,
    X_combined,
    y,
    lupi_features=None
)
</code></pre>

<h2 id="parameters_1">Parameters</h2>
<p>lupi_features : int
    Number of features in dataset which are considered privileged information (PI).
    PI features are expected to be the last features in the dataset.</p>
<p>??? example "View Source"
            def fit(self, X_combined, y, lupi_features=None):</p>
<pre><code>            """



            Parameters

            ----------

            lupi_features : int

                Number of features in dataset which are considered privileged information (PI).

                PI features are expected to be the last features in the dataset.



            """

            if lupi_features is None:

                raise ValueError("No lupi_features argument given.")

            self.lupi_features = lupi_features

            X, X_priv = split_dataset(X_combined, lupi_features)

            (n, d) = X.shape



            # Get parameters from CV model without any feature contstraints

            C = self.hyperparam["C"]

            epsilon = self.hyperparam["epsilon"]

            scaling_lupi_w = self.hyperparam["scaling_lupi_w"]

            scaling_lupi_loss = self.hyperparam["scaling_lupi_loss"]



            # Initalize Variables in cvxpy

            w = cvx.Variable(shape=(d), name="w")

            b = cvx.Variable(name="bias")

            w_priv_pos = cvx.Variable(lupi_features, name="w_priv_pos")

            b_priv_pos = cvx.Variable(name="bias_priv_pos")

            w_priv_neg = cvx.Variable(lupi_features, name="w_priv_neg")

            b_priv_neg = cvx.Variable(name="bias_priv_neg")

            slack = cvx.Variable(shape=(n), name="slack")



            # Define functions for better readability

            priv_function_pos = X_priv * w_priv_pos + b_priv_pos

            priv_function_neg = X_priv * w_priv_neg + b_priv_neg



            # Combined loss of lupi function and normal slacks, scaled by two constants

            priv_loss_pos = cvx.sum(priv_function_pos)

            priv_loss_neg = cvx.sum(priv_function_neg)

            priv_loss = priv_loss_pos + priv_loss_neg

            slack_loss = cvx.sum(slack)

            loss = scaling_lupi_loss * priv_loss + slack_loss



            # L1 norm regularization of both functions with 1 scaling constant

            weight_regularization = 0.5 * (

                cvx.norm(w, 1)

                + scaling_lupi_w

                * (0.5 * cvx.norm(w_priv_pos, 1) + 0.5 * cvx.norm(w_priv_neg, 1))

            )



            constraints = [

                y - X * w - b &lt;= epsilon + priv_function_pos + slack,

                X * w + b - y &lt;= epsilon + priv_function_neg + slack,

                priv_function_pos &gt;= 0,

                priv_function_neg &gt;= 0,

                # priv_loss_pos &gt;= 0,

                # priv_loss_neg &gt;= 0,

                # slack_loss &gt;= 0,

                slack &gt;= 0,

                # loss &gt;= 0,

            ]

            objective = cvx.Minimize(C * loss + weight_regularization)



            # Solve problem.

            solver_params = self.solver_params

            problem = cvx.Problem(objective, constraints)

            problem.solve(**solver_params)



            self.model_state = {

                "signs_pos": priv_function_pos.value &gt; 0,

                "signs_neg": priv_function_neg.value &gt; 0,

                "w": w.value,

                "w_priv_pos": w_priv_pos.value,

                "w_priv_neg": w_priv_neg.value,

                "b": b.value,

                "b_priv_pos": b_priv_pos.value,

                "b_priv_neg": b_priv_neg.value,

                "lupi_features": lupi_features,  # Number of lupi features in the dataset TODO: Move this somewhere else,

            }

            w_l1 = np.linalg.norm(w.value, ord=1)

            w_priv_pos_l1 = np.linalg.norm(w_priv_pos.value, ord=1)

            w_priv_neg_l1 = np.linalg.norm(w_priv_neg.value, ord=1)

            # We take the mean to combine all submodels (for priv) into a single normalization factor

            w_priv_l1 = w_priv_pos_l1 + w_priv_neg_l1

            self.constraints = {

                "priv_loss": priv_loss.value,

                "scaling_lupi_loss": scaling_lupi_loss,

                # "loss_slack": slack_loss.value,

                "loss": loss.value,

                "w_l1": w_l1,

                "w_priv_l1": w_priv_l1,

                "w_priv_pos_l1": w_priv_pos_l1,

                "w_priv_neg_l1": w_priv_neg_l1,

            }

            return self
</code></pre>
<h5 id="get_params">get_params</h5>
<pre><code class="python3">def get_params(
    self,
    deep=True
)
</code></pre>

<p>Get parameters for this estimator.</p>
<h2 id="parameters_2">Parameters</h2>
<p>deep : boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2 id="returns">Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p>
<p>??? example "View Source"
            def get_params(self, deep=True):</p>
<pre><code>            return self.hyperparam
</code></pre>
<h5 id="predict">predict</h5>
<pre><code class="python3">def predict(
    self,
    X
)
</code></pre>

<p>Method to predict points using svm classification rule.
We use both normal and priv. features.
This function is mainly used for CV purposes to find the best parameters according to score.</p>
<h2 id="parameters_3">Parameters</h2>
<p>X : numpy.ndarray</p>
<p>??? example "View Source"
            def predict(self, X):</p>
<pre><code>            """

            Method to predict points using svm classification rule.

            We use both normal and priv. features.

            This function is mainly used for CV purposes to find the best parameters according to score.



            Parameters

            ----------

            X : numpy.ndarray

            """

            X, X_priv = split_dataset(X, self.lupi_features)

            w = self.model_state["w"]

            b = self.model_state["b"]



            y = np.dot(X, w) + b



            return y
</code></pre>
<h5 id="score">score</h5>
<pre><code class="python3">def score(
    self,
    X,
    y,
    **kwargs
)
</code></pre>

<p>??? example "View Source"
            def score(self, X, y, **kwargs):</p>
<pre><code>            prediction = self.predict(X)

            _check_reg_targets(y, prediction, None)



            score = r2_score(y, prediction)

            return score
</code></pre>
<h5 id="set_params">set_params</h5>
<pre><code class="python3">def set_params(
    self,
    **params
)
</code></pre>

<p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2 id="returns_1">Returns</h2>
<p>self</p>
<p>??? example "View Source"
            def set_params(self, **params):</p>
<pre><code>            for p, value in params.items():

                self.hyperparam[p] = value

            return self
</code></pre>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../lupi_ordinal_regression/" title="Lupi Ordinal Regression" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Lupi Ordinal Regression
              </span>
            </div>
          </a>
        
        
          <a href="../ordinal_regression/" title="Ordinal Regression" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Ordinal Regression
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.c648116f.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
    
  </body>
</html>